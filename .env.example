# Deep Researcher Agent Configuration
# Copy this file to .env and modify the values as needed

# Application Settings
APP_NAME="Deep Researcher Agent"
APP_VERSION="1.0.0"
DEBUG=true
ENVIRONMENT=development

# Server Settings
HOST=0.0.0.0
PORT=8000
RELOAD=true

# API Settings
API_V1_PREFIX="/api/v1"
CORS_ORIGINS=["*"]

# Directory Paths (relative to project root)
DATA_DIR="./data"
UPLOADS_DIR="./data/uploads"
VECTORS_DIR="./data/vectors"
LOGS_DIR="./logs"

# AI/ML Model Settings
EMBEDDING_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"
# EMBEDDING_MODEL_CACHE_DIR="./models"  # Optional: cache directory for models
MAX_CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Vector Database Settings
VECTOR_INDEX_NAME="researcher_index"
SIMILARITY_THRESHOLD=0.7
MAX_SEARCH_RESULTS=10

# LangChain Settings (Optional)
# OPENAI_API_KEY="sk-your-openai-api-key-here"
# LANGCHAIN_TRACING_V2=false
# LANGCHAIN_PROJECT="researcher-agent"

# Groq LLM Settings (for Synthesis System)
# Groq LLM Settings (for Synthesis System)
GROQ_API_KEY="your_groq_api_key_here"
GROQ_MODEL_NAME="llama-3.1-8b-instant"
MAX_CONTEXT_TOKENS=8192
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4000

# Synthesis System Settings
SYNTHESIS_CONSENSUS_THRESHOLD=0.7
ASSERTION_MIN_SOURCES=2
ENABLE_CONTEXTUAL_COMPRESSION=true
RESPONSE_TIMEOUT=30

# Document Processing Settings
MAX_FILE_SIZE=52428800  # 50MB in bytes (50 * 1024 * 1024)
SUPPORTED_FILE_TYPES=[".pdf", ".txt", ".docx", ".md"]

# Logging Settings
LOG_LEVEL="INFO"
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
